# CheckStream Environment Configuration
# Copy this file to .env and customize for your environment

# Backend LLM API Configuration
BACKEND_URL=https://api.openai.com/v1
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...

# Server Configuration
LISTEN_ADDRESS=0.0.0.0
LISTEN_PORT=8080

# Policy Configuration
POLICY_PATH=./policies/default.yaml
# Or use a policy pack:
# POLICY_PACK=fca-consumer-duty

# Buffer Configuration
TOKEN_HOLDBACK=10
MAX_BUFFER_CAPACITY=1000

# Telemetry
TELEMETRY_ENABLED=true
TELEMETRY_MODE=aggregate  # aggregate or full

# Logging
RUST_LOG=checkstream=info,tower_http=debug
RUST_BACKTRACE=1

# Redis (optional, for distributed state)
REDIS_URL=redis://localhost:6379

# Prometheus Metrics
METRICS_PORT=9090

# Security
# TLS_CERT_PATH=/path/to/cert.pem
# TLS_KEY_PATH=/path/to/key.pem

# Admin API key for protected endpoints (/metrics, /audit, /tenants)
# Generate with: openssl rand -hex 32
CHECKSTREAM_ADMIN_API_KEY=

# Development mode (NEVER enable in production!)
# Allows localhost backends and disables SSRF protection
# CHECKSTREAM_DEV_MODE=1
